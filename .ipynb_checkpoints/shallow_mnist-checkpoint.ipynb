{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size :  60000\n",
      "Test set size :  10000\n"
     ]
    }
   ],
   "source": [
    "print('Train set size : ', X_train.shape[0])\n",
    "print('Test set size : ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at a random image in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd3679375c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd380158160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[552])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given image has digit 1\n"
     ]
    }
   ],
   "source": [
    "print(\"The given image has digit\", y_train[552])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening the pixel values into 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((60000,-1)) /255.0\n",
    "X_test = X_test.reshape((X_test.shape[0],-1)) /255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding on categorical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train after flattening: (60000, 784)\n",
      "Shape of y_train after one-hot encoding: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train after flattening:\", X_train.shape)\n",
    "print(\"Shape of y_train after one-hot encoding:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a neural net with 2 hidden layers each having 128 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Dense(128, input_shape=(784,)),\n",
    "                     Activation('relu'),\n",
    "                     Dense(128),\n",
    "                     Activation('relu'),\n",
    "                     Dense(10),\n",
    "                     Activation('softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model - train it for 2 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "45000/45000 [==============================] - 17s 375us/step - loss: 0.2644 - acc: 0.9212 - val_loss: 0.1408 - val_acc: 0.9584\n",
      "Epoch 2/2\n",
      "45000/45000 [==============================] - 6s 126us/step - loss: 0.1145 - acc: 0.9660 - val_loss: 0.1135 - val_acc: 0.9682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd36777a898>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2, batch_size=32, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 38us/step\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "Training accuracy: 97.73%\n",
      "Test accuracy: 97.06%\n"
     ]
    }
   ],
   "source": [
    "training_scores = model.evaluate(X_train, y_train)\n",
    "test_scores = model.evaluate(X_test, y_test)\n",
    "print(\"Training accuracy: {:.2f}%\".format(training_scores[1]*100))\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
